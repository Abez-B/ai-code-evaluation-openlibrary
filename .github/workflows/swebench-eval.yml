name: SWE-Bench Evaluation Workflow

on:
  push:
    branches:
      - main
  workflow_dispatch:
    inputs:
      task_id:
        description: 'Task ID to run'
        required: false
        default: 'internetarchive__openlibrary-c4eebe6677acc4629cb541a98d5e91311444f5d4'

permissions:
  contents: write

jobs:
  swe-bench-eval:
    runs-on: ubuntu-latest


    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Agent Dependencies
        run: |
          pip install requests pyyaml

      - name: Setup Target Repository
        run: |
          chmod +x setup_repository.sh
          bash setup_repository.sh

      - name: Run AI Agent (Claude)
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          python run_claude.py
          
      - name: Generate GitHub Actions Summary
        if: always()
        run: |
          echo "## ðŸ¤– SWE-bench Evaluation Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f result.json ]; then
            echo "### ðŸ“Š Metrics" >> $GITHUB_STEP_SUMMARY
            echo '```json' >> $GITHUB_STEP_SUMMARY
            cat result.json >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ Artifacts Generated" >> $GITHUB_STEP_SUMMARY
          echo "- agent.log" >> $GITHUB_STEP_SUMMARY
          echo "- prompts.log" >> $GITHUB_STEP_SUMMARY
          echo "- result.json" >> $GITHUB_STEP_SUMMARY
          echo "- pre_verification.log" >> $GITHUB_STEP_SUMMARY
          echo "- post_verification.log" >> $GITHUB_STEP_SUMMARY
          echo "- changes.patch" >> $GITHUB_STEP_SUMMARY

      - name: Extract Metrics
        if: always()
        run: |
          python extract_metrics.py

      - name: Upload Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: evaluation-artifacts
          path: |
            agent.log
            result.json
            pre_verification.log
            post_verification.log
            changes.patch
            prompts.log
            prompts.md
